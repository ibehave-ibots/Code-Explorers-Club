{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **A Short Introduction of Multiprocessing in Python**\n",
    "by Moritz Haustein \n",
    "\n",
    "05.03.2024\n",
    "\n",
    "### **Some general remarks on multiprocessing in Python**\n",
    "Generally, multiprocessing allows to split computational tasks in subtasks and their parallel processing on multiple CPU cores, which considerably shortens the processing time. A way to use multiprocessing in Python is by using the in-built **multiprocessing API**. <br><br>\n",
    "However, there are some pitfalls when useing **multiprocessing** in Python, e.g.: <br>\n",
    "1) Debugging can be a challenge as **print** or **try-except** statements are not displayed depending on the code editor used, as we will see that later in the examples! <br>\n",
    "2) In Jupiter notebooks, we have to import functions we want to use in multiprocessing from an external Python module. For this reason, I explain the function we want to use in a code block first, but import these functions from **codeLib.py** in the actual examples. <br>\n",
    "\n",
    "There are even more problems that you may have to deal with, but usually you can find a solution in the internet. So don't get frustrated right at the start! <br>\n",
    "Okay, after these first notes, I would like to show you some example how **multiprocessing** can be used in Python in the following sections. Furthermore, I have added a list of other multiprocessing tutorials which might be helpful to master multiprocessing in your code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import time\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The example: Counting the frequency of primes in a range of values**\n",
    "To demonstrate how multiprocessing works in Python, we first need a task which requires a lot of CPU time for execution and should therefore run faster if it is executed by multiple CPUs at the same time. Here, we will use the following CPU-bound task: counting the frequency of primes in a range of values.\n",
    "\n",
    "We will use two functions for this:\n",
    "1. **isPrimeNumber**: checks if an input value is a prime and returns True or False\n",
    "\n",
    "2. **countPrimesInRange**: loops through all values between the start and end and calls **isPrimeNumber** for each value. If the value is a prime number, it increments our counter variable **countOfPrimes** which is eventually returned after all values have been tested.\n",
    "\n",
    "These functions are both straightforward, but definitly not the most efficient way to accomplish the task. For example, while values divisible by 2 are processed quite fast, for very large prime number, e.g. 79,999, the whole for-loop must be run in **isPrimeNumber** and no other value can be checked until this is finished.\n",
    "\n",
    "In the first example, we will use only a single process for the task, i.e. this script will run only on one CPU. That allows us to see how much multiprocessing can speed up the calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of primes between 1 to 80000 is: 7837\n",
      "\n",
      "\n",
      "Processing time: 20.141 seconds\n"
     ]
    }
   ],
   "source": [
    "def isPrimeNumber(value):\n",
    "    if value < 2:\n",
    "        return False\n",
    "    for iCheckIfDivider in range(2, value):\n",
    "        if (value % iCheckIfDivider) == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def countPrimesInRange(startValue, endValue):\n",
    "    countOfPrimes = 0\n",
    "    for iValue in range(startValue, endValue + 1): #+1 required to test the endValue, too\n",
    "        if isPrimeNumber(iValue):\n",
    "            countOfPrimes += 1\n",
    "    return countOfPrimes\n",
    "\n",
    "#Main script\n",
    "#define range\n",
    "startValue = 1\n",
    "endValue = 80000\n",
    "\n",
    "#start processing\n",
    "startTime = time.perf_counter() \n",
    "countOfPrimes = countPrimesInRange(startValue, endValue)\n",
    "endTime = time.perf_counter()\n",
    "\n",
    "#print results\n",
    "print(\"Count of primes between %i to %i is: %i\\n\"%(startValue, endValue, countOfPrimes))\n",
    "print(\"\\nProcessing time: %.3f seconds\" %(endTime - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using Mutiprocessing: How to run a task in independent processes**\n",
    "Now let's see how fast we are when we divide the range of values into two tasks and have them processed by two independent workers, i.e. both work simulataneously on seperate CPU cores.\n",
    "1. For this, we first split the range of 1-80,000 into two tasks, i.e. **task_1** and **task_2**.\n",
    "\n",
    "2. Next we need to initate the two workers by using **mp.Process**. For this, we need to give *mp.Process* at least two arguments:\n",
    "     - **target**: this is the function the process should call. Important: only the name of the function without '()'\n",
    "     - **args**: the input arguments of the function we have assigned as **target**\n",
    "\n",
    " In principle, we could use **countPrimesInRange** as target function, but we will add some additional features in the function **countPrimesInRangeMP**:\n",
    " After counting all primes in a range, it will create and print a message as well as return the **countOfPrimes** together with the **message**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countPrimesInRangeMP(startValue, endValue):\n",
    "    countOfPrimes = countPrimesInRange(startValue, endValue) #call original counting function\n",
    "    \n",
    "    #print status of this worker\n",
    "    processID = os.getpid() #asks operation system for ID of process this function is running in\n",
    "    message = \"Worker (ID: %s) found %i primes from %i to %i\\n\"%(processID, countOfPrimes, startValue, endValue)\n",
    "    print(message)\n",
    "\n",
    "    return countOfPrimes, message #return both: the count value+ the message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single processes created with **mp.Process** can be stored in a \"variable\" so that we can access them later; in our example in  **worker1** and **worker2**.\n",
    "\n",
    "The workers have three important methods we can call:   \n",
    "    - **start()**: is used to start the processing. The worker will call *countPrimeNumbersInRangeMP* function with the start and end values as given by the tasks **1** and **2**. <br>\n",
    "    - **join()**: by calling **join()** we will wait until the worker is done with its task. That actually blocks our script from procceeding. If we would not use **join()**, the script would run until its end and terminate even when the workers are still running. <br>\n",
    "    - **close()**: will removes the additional computer resources used by the worker. That is not mandatory, but we will follow the Scout Rule: Keep your computer clean!   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initate workers...\n",
      "start processing...\n",
      "wait until workers are done...\n",
      "worker 1: done!\n",
      "worker 2: done!\n",
      "close workers\n",
      "Processing time: 15.642 seconds\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from codeLib import countPrimesInRangeMP \n",
    "\n",
    "#split range between [startValue, endValue] into 2 tasks for 2 workers (processes)\n",
    "task_1 = [1, 40000]\n",
    "task_2 = [40001, 80000]\n",
    "\n",
    "#initate two processes\n",
    "startTime = time.perf_counter()\n",
    "print('initate workers...')\n",
    "worker1 = mp.Process(target = countPrimesInRangeMP, args = (task_1[0], task_1[1])) #args: 1st is the startValue, 2nd is the endValue\n",
    "worker2 = mp.Process(target = countPrimesInRangeMP, args = (task_2[0], task_2[1]))\n",
    "\n",
    "#start processing\n",
    "print('start processing...')\n",
    "worker1.start()\n",
    "worker2.start()\n",
    "\n",
    "#wait until workers are done! Actually, \"join\" blocks the script from proceeding.\n",
    "print('wait until workers are done...')\n",
    "worker1.join() \n",
    "print('worker 1: done!')\n",
    "worker2.join()\n",
    "print('worker 2: done!')\n",
    "\n",
    "#close workers\n",
    "print('close workers')\n",
    "worker1.close()\n",
    "worker2.close()\n",
    "\n",
    "endTime = time.perf_counter()\n",
    "\n",
    "#print results\n",
    "print(\"Processing time: %.3f seconds\" %(endTime - startTime))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was already faster than in our single-proccess example. But why is not the message we created in **countPrimesInRangeMP** being printed? And there are our results?\n",
    "Whether you can see the messages printed by the workers depends on the IDE you are using. Unfortunately, we cannot see them in Jupyter notebooks. Also, there is no direct way to get results from the workers. What we need is a way to share data with the workers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ways of sharing data with processes**\n",
    "\n",
    "In the next example, we will use two ways of sharing data with the workers:\n",
    "1) **mp.Value**: allows to access a value in our main script as well as by the worker processess. We will initiate a **sharedValue** as integer starting at 0 by calling **mp.Value('i', 0)**. To access the stored value we have to use **sharedValue.value** later.\n",
    "\n",
    "2) **mp.Queue**: can store a list of variables. It operates as first-in-first-out (FIFO) buffer, i.e. the first variable stored is also the first variable you will get back. There are four methods of **mp.Queue** objects which we will use in our script:\n",
    "    - **put(var)**: insert variable in the queue. <br>\n",
    "    - **get()**: returns first variable stored in the queue and deletes it in the queue <br>\n",
    "    - **empty()**: ask if the queue is empty. Returns True (empty) or False (still variables stored) <br>\n",
    "    - **close()**: closing the queue at end of our script. Same as for **mp.Process** <br>\n",
    "\n",
    "\n",
    "We also have to modify our counting function and save it as **countPrimeNumbersInRange_withSharedVars**: <br>\n",
    "1) It now recieves also the **sharedValue** and the **messageQueue** as arguments. <br>\n",
    "2) After the worker has counted the primes, we add that result to the **sharedValue**. <br>\n",
    "3) Instead of printing the message, we put it now into the **messageQueue**, so we can print it later <br>\n",
    "4) The return statement is now removed, as we cannot use it anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countPrimeNumbersInRange_withSharedVars(startValue, endValue, sharedValue, messageQueue):\n",
    "    countOfPrimes = _countPrimesInRangeMP(startValue, endValue)\n",
    "    \n",
    "    #store numberOfPrimes in mp.Value\n",
    "    sharedValue.value += countOfPrimes\n",
    "    \n",
    "    #produce message\n",
    "    processID = os.getpid() \n",
    "    message = \"Worker (ID: %s) found %i primes from %i to %i\"%(processID, countOfPrimes , startValue, endValue)\n",
    "    \n",
    "    #store message in mp.Queue\n",
    "    messageQueue.put(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initate workers...\n",
      "start processing...\n",
      "block script until processing is done...\n",
      "worker 1: done!\n",
      "worker 2: done!\n",
      "close workers\n",
      "\n",
      "\n",
      "Number of primes between 1 to 80000 is: 7837\n",
      "\n",
      "worker stated following messages:\n",
      "Worker (ID: 13620) found 4203 primes from 1 to 40000\n",
      "Worker (ID: 20856) found 3634 primes from 40001 to 80000\n",
      "Processing time: 16.129 seconds\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from codeLib import countPrimesInRange_withSharedVars \n",
    "\n",
    "#created shared variable between processes; stores primes count from workers\n",
    "sharedValue = mp.Value('i', 0) # \"i\": integer, 0: starting value\n",
    "\n",
    "#create shared queue between processes; stores messages from workers\n",
    "messageQueue = mp.Queue() \n",
    "\n",
    "#split range between [startValue, endValue] into 2 tasks for 2 workers (processes)\n",
    "task_1 = [1, 40000]\n",
    "task_2 = [40001, 80000]\n",
    "\n",
    "startTime = time.perf_counter()\n",
    "\n",
    "print('initate workers...')\n",
    "worker1 = mp.Process(target = countPrimesInRange_withSharedVars, args = (task_1[0], task_1[1], sharedValue, messageQueue)) #added sharedValue, messageQueue as arguments\n",
    "worker2 = mp.Process(target = countPrimesInRange_withSharedVars, args = (task_2[0], task_2[1], sharedValue, messageQueue))\n",
    "\n",
    "#start processing\n",
    "print('start processing...')\n",
    "worker1.start()\n",
    "worker2.start()\n",
    "\n",
    "#wait until workers are done! \n",
    "print('block script until processing is done...')\n",
    "worker1.join()\n",
    "print('worker 1: done!')\n",
    "worker2.join()\n",
    "print('worker 2: done!')\n",
    "\n",
    "#close workers\n",
    "print('close workers')\n",
    "worker1.close()\n",
    "worker2.close()\n",
    "\n",
    "endTime = time.perf_counter()\n",
    "\n",
    "\n",
    "#print results\n",
    "numberOfPrimes = sharedValue.value #get the final count of primes\n",
    "startValue = task_1[0]\n",
    "endValue = task_2[1]\n",
    "print('\\n')\n",
    "print(\"Number of primes between %i to %i is: %i\\n\"%(startValue, endValue, numberOfPrimes))\n",
    "print(\"worker stated following messages:\")\n",
    "while not messageQueue.empty(): #asking to loop through whole queue by asking if it is empty\n",
    "    message = messageQueue.get() #retrive a message from the queue\n",
    "    print(message)\n",
    "\n",
    "#close the queue, too\n",
    "messageQueue.close() \n",
    "\n",
    "print(\"Processing time: %.3f seconds\" %(endTime - startTime))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using more than two workers in an automatized fashion**\n",
    "\n",
    "Next, we will try to use more workers to improve performance even further. Of course, we could just copy/paste our code for each new worker, but it would be more elegant to have an automated solution.\n",
    "For this, we need to:\n",
    "1) have a variable which we name **numbersOfWorkers** that we use to set the number of workers we want\n",
    "2) split our range into as many tasks as we have workers\n",
    "3) create an empty list called **workerCollection** in which we store all new workers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The splitArrs looks like:\n",
      "[    1     2     3 ... 19998 19999 20000]\n",
      "[20001 20002 20003 ... 39998 39999 40000]\n",
      "[40001 40002 40003 ... 59998 59999 60000]\n",
      "[60001 60002 60003 ... 79998 79999 80000]\n",
      "The tasks looks like:\n",
      "[1, 20000]\n",
      "[20001, 40000]\n",
      "[40001, 60000]\n",
      "[60001, 80000]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#how can we automatically split the tasks for different numbers of workers\n",
    "startValue = 1\n",
    "endValue = 80000\n",
    "numberOfWorkers = 4\n",
    "\n",
    "#code for splitting the tasks\n",
    "def splitRangeIntoTasks(startValue, endValue, numberOfWorkers):\n",
    "    splitArrs = np.array_split(np.arange(startValue, endValue + 1), numberOfWorkers)\n",
    "    tasks = [[i[0], i[-1]] for i in splitArrs]\n",
    "    return tasks, splitArrs\n",
    "\n",
    "tasks, splitArrs = splitRangeIntoTasks(startValue, endValue, numberOfWorkers)\n",
    "\n",
    "print('The splitArrs looks like:')\n",
    "for iSplit in splitArrs:\n",
    "    print(iSplit)\n",
    "print('The tasks looks like:')\n",
    "for iTask in tasks:\n",
    "    print(iTask)\n",
    "print('----------')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use a for-loop to loop through our tasks and create a worker in each iteration which we store by appending it to our **workerCollection** list.\n",
    "Afterwards, we can loop through our **workerCollection** to start, join, and close the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initate workers...\n",
      "start processing...\n",
      "block script until processing is done...\n",
      "worker 0 : done and is closed!\n",
      "worker 1 : done and is closed!\n",
      "worker 2 : done and is closed!\n",
      "worker 3 : done and is closed!\n",
      "\n",
      "\n",
      "Number of primes between 1 to 80000 is: 7837\n",
      "\n",
      "worker stated following messages:\n",
      "Worker (ID: 12212) found 2262 primes from 1 to 20000\n",
      "Worker (ID: 15640) found 1941 primes from 20001 to 40000\n",
      "Worker (ID: 21704) found 1854 primes from 40001 to 60000\n",
      "Worker (ID: 10268) found 1780 primes from 60001 to 80000\n",
      "Processing time: 10.325 seconds\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from codeLib import splitRangeIntoTasks, countPrimesInRange_withSharedVars #this is required for Jupyiter notebook (and other IDEs; mostly on Windows) to work with multiprocessing\n",
    "\n",
    "#created shared variable between processes; stores primes count from workers\n",
    "sharedValue = mp.Value('i', 0) # \"i\": integer, 0: starting value\n",
    "\n",
    "#create shared queue between processes; stores print messages from workers\n",
    "messageQueue = mp.Queue() \n",
    "\n",
    "#define number of workers\n",
    "numberOfWorkers = 4 #8\n",
    "\n",
    "#split range between startValue/endValue into multiple tasks\n",
    "tasks = splitRangeIntoTasks(startValue, endValue, numberOfWorkers)\n",
    "\n",
    "\n",
    "startTime = time.perf_counter()\n",
    "print('initate workers...')\n",
    "workerCollection = []\n",
    "for iTask in tasks: #loop through tasks\n",
    "    worker = mp.Process(target = countPrimesInRange_withSharedVars, args = (iTask[0], iTask[1], sharedValue, messageQueue))\n",
    "    workerCollection.append(worker)\n",
    "\n",
    "#start processing\n",
    "print('start processing...')\n",
    "for iWorker in workerCollection:\n",
    "    iWorker.start()\n",
    "\n",
    "#wait until workers are done! Actually, \"join\" blocks the script from proceeding.\n",
    "print('block script until processing is done...')\n",
    "for iWorkerID, iWorker in enumerate(workerCollection):\n",
    "    iWorker.join() #block worker\n",
    "    iWorker.close() #close worker directly\n",
    "    print('worker %i : done and is closed!'%iWorkerID)\n",
    "numberOfPrimes = sharedValue.value\n",
    "\n",
    "\n",
    "endTime = time.perf_counter()\n",
    "\n",
    "#print results\n",
    "print('\\n')\n",
    "print(\"Number of primes between %i to %i is: %i\\n\"%(startValue, endValue, numberOfPrimes))\n",
    "print(\"worker stated following messages:\")\n",
    "while not messageQueue.empty():\n",
    "    message = messageQueue.get()\n",
    "    print(message)\n",
    "messageQueue.close()\n",
    "\n",
    "print(\"Processing time: %.3f seconds\" %(endTime - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the processing was even faster than using only two workers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Simplify things with mp.Pool**\n",
    "\n",
    "That's a lot of code. But there is a much simpler way to use multiprocessing: The \"Pool\" class\n",
    "\n",
    "This interface handles a lot of responsability for us:\n",
    "- it catches the return of each workers, so we don't need shared variables or queues <br>\n",
    "- automatically start and join the workers for us <br>\n",
    "- the closing of the Pool can be ensured by using Context-Manager, i.e. using the with-statement <br>\n",
    "\n",
    "To initiate a multiprocessing **Pool** you can simply call **mp.Pool(*number_of_wanted_workers*)** and store it in a *variable*; however, as we will use the context manager, we have to use the following syntax: **with mp.Pool(numberOfWorker) as workerPool:**. \n",
    "That allows us to start all workers by calling the **map** or **starmap** methods from the **Pool** class. If you look into the code below, you will hopefully see that it is quite similar to our for-loop to initate/collect workers in the last section!\n",
    "Importantly, the results of a **Pool** are stored in a list, i.e. each item in the list is the return from the function we put into the **workerPool** for each worker. If there is more than one returned variable, all outputs will be stored in a tuple. <br>\n",
    "\n",
    "A final note: the rule of thumb is that you should use always the number of CPU cores available in your system. To do this, we can simply call **mp.cpu_count()**!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of CPUs: 20\n",
      "Initate worker pool and start processing...\n",
      "\n",
      "\n",
      "Number of primes from 1 to 80000 is: 7837\n",
      "Worker returned following counts: [550, 457, 431, 424, 400, 406, 387, 377, 392, 379, 376, 367, 373, 364, 374, 356, 361, 354, 356, 353]\n",
      "worker stated following messages:\n",
      "Worker (ID: 21788) found 550 primes from 1 to 4000\n",
      "Worker (ID: 18780) found 457 primes from 4001 to 8000\n",
      "Worker (ID: 16992) found 431 primes from 8001 to 12000\n",
      "Worker (ID: 22380) found 424 primes from 12001 to 16000\n",
      "Worker (ID: 20788) found 400 primes from 16001 to 20000\n",
      "Worker (ID: 17036) found 406 primes from 20001 to 24000\n",
      "Worker (ID: 14788) found 387 primes from 24001 to 28000\n",
      "Worker (ID: 14856) found 377 primes from 28001 to 32000\n",
      "Worker (ID: 10372) found 392 primes from 32001 to 36000\n",
      "Worker (ID: 15164) found 379 primes from 36001 to 40000\n",
      "Worker (ID: 16088) found 376 primes from 40001 to 44000\n",
      "Worker (ID: 15304) found 367 primes from 44001 to 48000\n",
      "Worker (ID: 5212) found 373 primes from 48001 to 52000\n",
      "Worker (ID: 15704) found 364 primes from 52001 to 56000\n",
      "Worker (ID: 3056) found 374 primes from 56001 to 60000\n",
      "Worker (ID: 19368) found 356 primes from 60001 to 64000\n",
      "Worker (ID: 21760) found 361 primes from 64001 to 68000\n",
      "Worker (ID: 13128) found 354 primes from 68001 to 72000\n",
      "Worker (ID: 1260) found 356 primes from 72001 to 76000\n",
      "Worker (ID: 6120) found 353 primes from 76001 to 80000\n",
      "Processing time: 3.033 seconds\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from codeLib import splitRangeIntoTasks, countPrimesInRangeMP\n",
    "\n",
    "\n",
    "#define number of workers: rule of tumb: for best results use the number of CPUs available in your system\n",
    "numberOfWorkers = mp.cpu_count() \n",
    "print(\"number of CPUs: %i\" % numberOfWorkers)\n",
    "\n",
    "\n",
    "\n",
    "#split range between startValue/endValue into multiple tasks\n",
    "startValue = 1\n",
    "endValue = 80000\n",
    "tasks = splitRangeIntoTasks(startValue, endValue, numberOfWorkers)\n",
    "\n",
    "\n",
    "\n",
    "startTime = time.perf_counter()\n",
    "#initate/process with Pool\n",
    "print('Initate worker pool and start processing...')\n",
    "\n",
    "with mp.Pool(numberOfWorkers) as workerPool: \n",
    "    resultsFromWorkers = workerPool.starmap(countPrimesInRangeMP, tasks) #use 'starmap' for multiple arguments for the function; use 'map' for single arguments \n",
    "\n",
    "\n",
    "#Merge the single results for the workers \n",
    "#resultsFromWorkers is a list, each worker returned a tuple with (numberOfPrimes, message)\n",
    "countedPimesByWorker, messages = [], []\n",
    "for iNumberOfPrimes, iMessage in resultsFromWorkers:\n",
    "    countedPimesByWorker.append(iNumberOfPrimes)\n",
    "    messages.append(iMessage)\n",
    "numberOfPrimes = np.sum(countedPimesByWorker)\n",
    "\n",
    "endTime = time.perf_counter()\n",
    "\n",
    "#print results\n",
    "print('\\n')\n",
    "print(\"Number of primes from %i to %i is: %i\"%(startValue, endValue, numberOfPrimes))\n",
    "print(\"Worker returned following counts: %s\" % countedPimesByWorker)\n",
    "print(\"worker stated following messages:\")\n",
    "for iMessage in messages:\n",
    "    print(iMessage)\n",
    "\n",
    "print(\"Processing time: %.3f seconds\" %(endTime - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the proccesing time is much shorter than in the examples above if all available CPU cores are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **More advanced: Writing your own Process classes**\n",
    "\n",
    "Here I would like to give you an idea how you can write your own process classes. That allows you to create own processes that run in the background in your program and can do calculations or control devices as required. For example, you could outsource the control of a video camera: The camera can started/stopped and collects all video frames in the memory during acqusition, while your main programm can do other things. <br>\n",
    "However, object-oriented programming is a topic in itself, and describing how this exactly works in Python is beyond the scope of this tutorial. But there are many tutorials about it online; so just google it!\n",
    "<br>\n",
    "To create a own process class, you simply have to inhere the main functionality of **mp.Process** in your own class by:\n",
    "1) call: class **Name_of_your_class(mp.Process)**\n",
    "2) call **super().__init__()** in the **__init__** method of your class\n",
    "\n",
    "Afterwards, your class has the same methods as **mp.Process** has, e.g. **start()**, **join()**, and **close()**. \n",
    "Importantly, you don't have to give your class a function as **target** argument, but rather you have to write your function into the **run** method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "class OwnWorker(mp.Process): #we inherit the basic functionality such as start, join, close methods from mp.Process\n",
    "    def __init__(self): #is called when object is created\n",
    "        super().__init__() #required to inherit functions from mp.Process  \n",
    "        \n",
    "    def run(self): #this method is called when the user \n",
    "        pass\n",
    "        #do stuff here\n",
    "        \n",
    "worker = OwnWorker()\n",
    "worker.start()\n",
    "worker.join()\n",
    "worker.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next example, we will define a Worker that performs a simple task: It adds a 1 to each value of a task-list and stores it in **self.results**. The task-list is passed to the worker during initialisation, i.e. by calling **worker = OwnWorker1(tasks)**, and stored in **self.tasks**. To start processing, we can use the **start**-method by calling **worker.start()**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OwnWorker1(mp.Process):\n",
    "    def __init__(self, tasks):\n",
    "        super().__init__()       \n",
    "        self.tasks = tasks\n",
    "        self.results = []\n",
    "\n",
    "    def run(self):\n",
    "        for iValue in self.tasks:\n",
    "            incValue = iValue + 1\n",
    "            self.results.append(incValue)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, now the results will be stored in **worker.results**. But can we access those from the main script?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: []\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from codeLib import OwnWorker1 \n",
    "\n",
    "tasks = [0, 1, 2, 3, 4, 5]\n",
    "worker = OwnWorker1(tasks)\n",
    "worker.start()\n",
    "worker.join()\n",
    "worker.close()\n",
    "results = worker.results\n",
    "print(\"Results: %s\"%results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortuntatly not! When we try to access **worker.results**, we only get an empty list. We again need some kind of communication between the worker process and the main programm, as we needed in the first examples of this tutorial. However, this time we use a **Pipe**.<br>\n",
    "A pipe acutally offers a two-way communiction, meaning that we can send data or recieve data from the worker and from the main script. For this, you get two pipe objects back when you call **mp.Pipe()**, e.g. **pipeMain, pipeWorker = mp.Pipe()**. Both, **pipeMain** and **pipeWorker** have the same methods you can call: <br>\n",
    "- **send**: used to send data from one pipe to the other pipe object <br>\n",
    "- **recv**: used to recv data by one pipe if the other pipe has send data <br>\n",
    "- **poll**: ask if there was send data from one pipe to the other. Here you can also define a **timeout** in seconds, i.e. the pipe will wait a certain time for data from the other pipe. This is important as sending data requires some time and you might miss that data when you just call **recv()**<br><br>\n",
    "\n",
    "To demonstrate how you can use pipes for communication, we write a new process class with the name **OwnWorker2**: <br>\n",
    "1) The **pipeWorker** is passed to the class during initialisation by calling **worker = OwnWorker2(pipeWorker)**. We also define a **self.isRunning = True** boolean variable in **__init__** method, which allows us to control whether the worker is active or closed <br>\n",
    "2) In the **run** method, we define a while-loop that will run infinitely as long as **self.isRunning** is True. In the while loop we when ask if there are any data send from the main programm to the **pipeWorker** by calling **if self.pipeworker.poll(timeout=0.5)**. If there is data, we will recive the data by calling **task = self.pipeWorker.recv()** followed by asking which type of task was send. If it is the string variable **'close'** we set **self.isRunning** to False which will finally break the while-loop and close the worker. If it is not a string, we presume it is a list of values which we want to process. After processing, we send the results back to the main programm via **self.pipeWorker.send(results)** <br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OwnWorker2(mp.Process):\n",
    "    def __init__(self, pipeWorker):\n",
    "        super().__init__()       \n",
    "        self.pipeWorker = pipeWorker\n",
    "        self.isRunning = True\n",
    "\n",
    "    def run(self):\n",
    "        while self.isRunning:\n",
    "            if self.pipeWorker.poll(timeout=0.5): #timeout is important, if not CPU load gets to 100%, alternative: use time.sleep(0.5)\n",
    "                task = self.pipeWorker.recv()\n",
    "                if isinstance(task, str): #check if close signal was send\n",
    "                    if task == 'close':\n",
    "                        self.isRunning = False\n",
    "                else: #process the data\n",
    "                    results = []\n",
    "                    for iValue in task:\n",
    "                        incValue = iValue + 1\n",
    "                        results.append(incValue)\n",
    "                        self.pipeWorker.send(results)\n",
    "    \n",
    "            #time.sleep(0.5)\n",
    "\n",
    "        self.pipeWorker.send('worker is closed!')\n",
    "        self.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can write our main programm. We first initate our pipes. The **pipeWorker** is used as argument during initialisation of our worker by calling **worker = OwnWorker2(pipeWorker)**, while **pipeMain** is used in the main programm to communicate with the worker. After starting the worker by calling **worker.start()**, it will wait for tasks. We will send two tasks to the worker by calling **pipeMain.send(task1)** and **pipeMain.send(task1)**. Afterwards, we will ask if the worker has processed the data by calling **if pipeMail.poll(timeout=2)**, meaning we wait up to 2 seconds before we try to recieve the results from the worker by calling **pipeMain.recv()**. Between the tasks, we use **time.sleep** to simulate additional computations before the next task is ready for the worker. In a final step, we send **'close'** to the worker via **pipeMain** to terminate the worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep for 1 second\n",
      "results for task1: [1, 2, 3, 4, 5, 6] \n",
      "sleep for 1 second\n",
      "results for task2: [6, 6, 6, 2] \n",
      "sleep for 1 second\n",
      "worker is closed!\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from codeLib import OwnWorker2\n",
    "\n",
    "\n",
    "#we use a Pipe to communicate with our worker\n",
    "pipeMain, pipeWorker = mp.Pipe()\n",
    "\n",
    "\n",
    "#initate worker\n",
    "worker = OwnWorker2(pipeWorker)\n",
    "worker.start()\n",
    "print('sleep for 1 second')\n",
    "time.sleep(1)\n",
    "\n",
    "#send tasks to worker\n",
    "task1 = [0, 1, 2, 3, 4, 5]\n",
    "pipeMain.send(task1)\n",
    "if pipeMain.poll(timeout=2):\n",
    "    results = pipeMain.recv()\n",
    "    print(\"results for task1: %s \"%results)\n",
    "\n",
    "print('sleep for 1 second')\n",
    "time.sleep(1)\n",
    "\n",
    "#send tasks to worker\n",
    "task2 = [5,5,5,1]\n",
    "pipeMain.send(task2)\n",
    "if pipeMain.poll(timeout=2):\n",
    "    results = pipeMain.recv()\n",
    "    print(\"results for task2: %s \"%results)\n",
    "\n",
    "print('sleep for 1 second')\n",
    "time.sleep(1)\n",
    "\n",
    "#close worker\n",
    "pipeMain.send('close')\n",
    "if pipeMain.poll(timeout=2):\n",
    "    msg = pipeMain.recv()\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it is relatively easy to construct your own **mp.Process** class, keep it active as long as necessary, and process data whenever it is available. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some additional sources about multiprocessing in Python: <br>\n",
    "https://superfastpython.com/multiprocessing-in-python/ <br>\n",
    "https://zetcode.com/python/multiprocessing/ <br>\n",
    "https://medium.com/@shahooda637/multi-processing-in-python-32d4b1c97354 <br>\n",
    "https://pymotw.com/2/multiprocessing/basics.html <br>\n",
    "https://www.machinelearningplus.com/python/parallel-processing-python/ <br>\n",
    "https://medium.com/contentsquare-engineering-blog/multithreading-vs-multiprocessing-in-python-ece023ad55a <br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
